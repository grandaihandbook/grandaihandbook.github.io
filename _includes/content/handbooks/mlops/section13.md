---
layout: default
title: "Evaluation and Benchmarking"
description: "Assessing MLOps systems and their outputs."
---

<link rel="stylesheet" href="{{ '/assets/css/section-academic.css' | relative_url }}">

Chapter 49: Model Performance Metrics
Latency, throughput, accuracy
Domain-specific KPIs: Precision@K, MAP
Chapter 50: MLOps Benchmarks
Datasets: DAWNBench, MLPerf
Leaderboards: Papers With Code
Chapter 51: Robustness and Stress Testing
Adversarial attacks
Out-of-distribution testing
Tools: Foolbox, RobustBench
Chapter 52: Human-in-the-Loop Evaluation
Active learning
Crowdsourcing
Platforms: Amazon Mechanical Turk, Labelbox

<script>
  // Navigation variables - no previous for index
  window.prevSection = "/content/handbooks/foundation-models/section13/";
  window.nextSection = "/content/handbooks/foundation-models/section15/";
</script>

<script src="{{ '/assets/js/section-academic.js' | relative_url }}"></script>
