---
layout: default
title: "Multi-Agent and Game-Theoretic RL"
description: "A study of QMIX and zero-sum games, where multiple agents interact in cooperative or competitive settings."
---

<link rel="stylesheet" href="{{ '/assets/css/section-academic.css' | relative_url }}">

Chapter 22: Multi-Agent RL Basics
Problem Definition and Research Motivation
Research Directions: Cooperative, competitive, mixed settings
Frameworks: MARL challenges, agent modeling
Future Study: Scalable MARL, real-world coordination
References
Chapter 23: Decentralized and Centralized Training
Independent Q-learning, QMIX, WQMIX
COMA, QTRAN, CollaQ, ATOC
Centralized Training with Decentralized Execution
References
Chapter 24: Game-Theoretic RL
(Nash equilibria, Stackelberg games, mean-field games)
Chapter 25: Zero-Sum Games
Problem Definition and Research Motivation
Research History: Minimax, AlphaGo, poker solvers
Algorithms: CFR, fictitious play, neural MCTS
Future Prospects: General-sum extensions, real-time games
References
Chapter 26: Emergent Behaviors in MARL
(Coordination, communication, social dilemmas)

<script>
  // Navigation variables
  var prevSection = "/content/handbooks/generative-ai/index.md";
  var nextSection = "/content/handbooks/generative-ai/section2.md";
</script>

<script src="{{ '/assets/js/section-academic.js' | relative_url }}"></script>
