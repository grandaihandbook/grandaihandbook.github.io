<link rel="stylesheet" href="/assets/css/research/landmark-papers.css">

<div class="landmark-papers-container">
  <div class="landmark-header">
    <h1>Landmark Papers in LLMs</h1>
    <p>Explore the foundational research that has shaped the field of Large Language Models. This curated collection highlights the most influential papers that established key concepts, techniques, and breakthroughs in the evolution of LLMs.</p>
  </div>
  <div class="attribution-notice">
    <div class="attribution-content">
      <p>Landmark Papers in LLMs is a curated collection showcasing the foundational research that has shaped the field of large language models. I've carefully selected these papers to highlight the key breakthroughs and conceptual advances that have defined the evolution of LLMs, providing historical context and significance for researchers and enthusiasts alike.</p>
    </div>
  </div>
  <div class="year-section">
    <h2 class="year-heading">2017</h2>
    
    <div class="timeline">
      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">June 2017</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Transformers</span>
              <span class="landmark-tag">Attention</span>
            </div>
          </div>
          <h3 class="landmark-title">Attention Is All You Need</h3>
          <p class="landmark-significance">This paper introduced the Transformer architecture, replacing recurrence and convolutions with attention mechanisms, revolutionizing sequence modeling and establishing the foundation for all subsequent large language models through its efficiency, parallelizability, and capacity to capture long-range dependencies.</p>
          <a href="https://arxiv.org/abs/1706.03762" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>
    </div>
  </div>

  <div class="year-section">
    <h2 class="year-heading">2018</h2>
    
    <div class="timeline">
      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">October 2018</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Bidirectional</span>
              <span class="landmark-tag">Pre-training</span>
            </div>
          </div>
          <h3 class="landmark-title">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</h3>
          <p class="landmark-significance">BERT revolutionized NLP by introducing bidirectional pre-training and demonstrating the effectiveness of the pre-train then fine-tune paradigm, achieving state-of-the-art results across numerous tasks and initiating a new era of transformer-based language models.</p>
          <a href="https://arxiv.org/abs/1810.04805" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>

      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">June 2018</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Pre-training</span>
              <span class="landmark-tag">Transfer Learning</span>
            </div>
          </div>
          <h3 class="landmark-title">Improving Language Understanding by Generative Pre-Training</h3>
          <p class="landmark-significance">GPT-1 established the effectiveness of generative pre-training followed by discriminative fine-tuning for language tasks, demonstrating that a single pre-trained model could serve as a foundation for multiple downstream applications with minimal task-specific architecture modifications.</p>
          <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>
    </div>
    <div class="year-section">
    <h2 class="year-heading">2019</h2>
    <div class="timeline">
      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">February 2019</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Unsupervised Learning</span>
              <span class="landmark-tag">Multitask Learning</span>
            </div>
          </div>
          <h3 class="landmark-title">Language Models are Unsupervised Multitask Learners</h3>
          <p class="landmark-significance">GPT-2 demonstrated that large-scale unsupervised pre-training could enable a single model to perform well across diverse tasks without task-specific fine-tuning, showcasing the power of scaling language models for generalization.</p>
          <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>
      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">September 2019</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Model Parallelism</span>
              <span class="landmark-tag">Scaling</span>
            </div>
          </div>
          <h3 class="landmark-title">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</h3>
          <p class="landmark-significance">Megatron-LM introduced efficient model parallelism techniques, enabling the training of multi-billion parameter language models and setting the stage for scaling LLMs to unprecedented sizes.</p>
          <a href="https://arxiv.org/abs/1909.08053" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>
      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">October 2019</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Text-to-Text</span>
              <span class="landmark-tag">Transfer Learning</span>
            </div>
          </div>
          <h3 class="landmark-title">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</h3>
          <p class="landmark-significance">T5 reframed all NLP tasks as text-to-text problems, demonstrating that a single transformer model could achieve state-of-the-art performance across diverse tasks through unified pre-training and fine-tuning.</p>
          <a href="https://arxiv.org/abs/1910.10683" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>
      <div class="landmark-card">
        <div class="landmark-card-content">
          <div class="landmark-meta">
            <span class="landmark-date">October 2019</span>
            <div class="landmark-tags">
              <span class="landmark-tag">Memory Optimization</span>
              <span class="landmark-tag">Scaling</span>
            </div>
          </div>
          <h3 class="landmark-title">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</h3>
          <p class="landmark-significance">ZeRO introduced memory-efficient training techniques, such as optimizer state and gradient partitioning, enabling the training of trillion-parameter models by reducing GPU memory requirements.</p>
          <a href="https://arxiv.org/abs/1910.02054" class="landmark-read-more">
            Read Paper
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
          </a>
        </div>
      </div>
    </div>
    </div>

    <div class="year-section">
      <h2 class="year-heading">2020</h2>
      <div class="timeline">
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">January 2020</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Scaling Laws</span>
                <span class="landmark-tag">Performance Prediction</span>
              </div>
            </div>
            <h3 class="landmark-title">Scaling Laws for Neural Language Models</h3>
            <p class="landmark-significance">This paper formalized scaling laws for language models, showing predictable relationships between model size, dataset size, and compute, guiding the design of larger and more efficient LLMs.</p>
            <a href="https://arxiv.org/abs/2001.08361" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">May 2020</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Few-Shot Learning</span>
                <span class="landmark-tag">Scaling</span>
              </div>
            </div>
            <h3 class="landmark-title">Language Models are Few-Shot Learners</h3>
            <p class="landmark-significance">GPT-3 showcased the power of large-scale language models in few-shot learning, performing complex tasks with minimal examples and highlighting the emergent capabilities of massive LLMs.</p>
            <a href="https://arxiv.org/abs/2005.14165" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
      </div>
    </div>

    <div class="year-section">
      <h2 class="year-heading">2021</h2>
      <div class="timeline">
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">January 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Sparsity</span>
                <span class="landmark-tag">Scaling</span>
              </div>
            </div>
            <h3 class="landmark-title">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</h3>
            <p class="landmark-significance">Switch Transformers introduced sparse mixture-of-experts models, enabling efficient scaling to trillion-parameter models with reduced computational costs.</p>
            <a href="https://arxiv.org/abs/2101.03961" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">August 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Code Generation</span>
                <span class="landmark-tag">Pre-training</span>
              </div>
            </div>
            <h3 class="landmark-title">Evaluating Large Language Models Trained on Code</h3>
            <p class="landmark-significance">Codex demonstrated the ability of LLMs to generate high-quality code, paving the way for AI-assisted programming and the development of tools like GitHub Copilot.</p>
            <a href="https://arxiv.org/abs/2107.03374" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">August 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Foundation Models</span>
                <span class="landmark-tag">Ethics</span>
              </div>
            </div>
            <h3 class="landmark-title">On the Opportunities and Risks of Foundation Models</h3>
            <p class="landmark-significance">This paper coined the term "foundation models" and analyzed their societal implications, highlighting opportunities and risks in scalability, generalization, and ethical considerations.</p>
            <a href="https://arxiv.org/abs/2108.07258" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">September 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Zero-Shot Learning</span>
                <span class="landmark-tag">Instruction Tuning</span>
              </div>
            </div>
            <h3 class="landmark-title">Finetuned Language Models are Zero-Shot Learners</h3>
            <p class="landmark-significance">FLAN showed that instruction tuning could significantly improve zero-shot performance, enabling LLMs to generalize to unseen tasks with natural language instructions.</p>
            <a href="https://arxiv.org/abs/2109.01652" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">October 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Multitask Learning</span>
                <span class="landmark-tag">Zero-Shot Learning</span>
              </div>
            </div>
            <h3 class="landmark-title">Multitask Prompted Training Enables Zero-Shot Task Generalization</h3>
            <p class="landmark-significance">T0 demonstrated that multitask prompted training could enable LLMs to perform zero-shot generalization across a wide range of tasks, advancing prompt-based learning.</p>
            <a href="https://arxiv.org/abs/2110.08207" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">December 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Mixture-of-Experts</span>
                <span class="landmark-tag">Efficiency</span>
              </div>
            </div>
            <h3 class="landmark-title">GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</h3>
            <p class="landmark-significance">GLaM introduced a mixture-of-experts approach to scale LLMs efficiently, achieving high performance with lower computational costs compared to dense models.</p>
            <a href="https://arxiv.org/abs/2112.06905" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">December 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Human Feedback</span>
                <span class="landmark-tag">Question Answering</span>
              </div>
            </div>
            <h3 class="landmark-title">WebGPT: Browser-assisted question-answering with human feedback</h3>
            <p class="landmark-significance">WebGPT combined LLMs with web browsing and human feedback to improve the accuracy and relevance of question-answering, paving the way for more reliable AI assistants.</p>
            <a href="https://arxiv.org/abs/2112.09332" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">December 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Retrieval-Augmented</span>
                <span class="landmark-tag">Scaling</span>
              </div>
            </div>
            <h3 class="landmark-title">Improving language models by retrieving from trillions of tokens</h3>
            <p class="landmark-significance">Retro introduced retrieval-augmented language models, enhancing performance by accessing external data during inference, improving factual accuracy and context awareness.</p>
            <a href="https://arxiv.org/abs/2112.04426" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
        <div class="landmark-card">
          <div class="landmark-card-content">
            <div class="landmark-meta">
              <span class="landmark-date">December 2021</span>
              <div class="landmark-tags">
                <span class="landmark-tag">Scaling</span>
                <span class="landmark-tag">Analysis</span>
              </div>
            </div>
            <h3 class="landmark-title">Scaling Language Models: Methods, Analysis & Insights from Training Gopher</h3>
            <p class="landmark-significance">Gopher provided insights into scaling LLMs, analyzing performance trade-offs and demonstrating the importance of data quality and model size for achieving high performance.</p>
            <a href="https://arxiv.org/abs/2112.11446" class="landmark-read-more">
              Read Paper
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
            </a>
          </div>
        </div>
      </div>
    </div>
    <div class="year-section">

  <h2 class="year-heading">2022</h2>
  <div class="timeline">
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Reasoning</span>
            <span class="landmark-tag">Prompting</span>
          </div>
        </div>
        <h3 class="landmark-title">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h3>
        <p class="landmark-significance">This paper introduced chain-of-thought prompting, enabling LLMs to solve complex reasoning tasks by generating intermediate reasoning steps, dramatically improving performance on mathematical and logical problems.</p>
        <a href="https://arxiv.org/abs/2201.11903" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Dialogue</span>
            <span class="landmark-tag">Safety</span>
          </div>
        </div>
        <h3 class="landmark-title">LaMDA: Language Models for Dialog Applications</h3>
        <p class="landmark-significance">LaMDA introduced a specialized dialogue model focusing on quality, safety, and groundedness, setting new standards for conversational AI and highlighting the importance of responsibility in LLM deployment.</p>
        <a href="https://arxiv.org/abs/2201.08239" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Mathematical Reasoning</span>
            <span class="landmark-tag">Specialized LLM</span>
          </div>
        </div>
        <h3 class="landmark-title">Solving Quantitative Reasoning Problems with Language Models</h3>
        <p class="landmark-significance">Minerva demonstrated that LLMs could solve complex mathematical and scientific problems with high accuracy when fine-tuned on technical content, advancing the frontier of AI for STEM applications.</p>
        <a href="https://arxiv.org/abs/2206.14858" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Model Parallelism</span>
            <span class="landmark-tag">Industry Collaboration</span>
          </div>
        </div>
        <h3 class="landmark-title">Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model</h3>
        <p class="landmark-significance">This paper detailed the training of one of the largest LLMs at the time, showcasing advanced parallel computing techniques and industry collaboration in scaling language models.</p>
        <a href="https://arxiv.org/abs/2201.11990" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">March 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">RLHF</span>
            <span class="landmark-tag">Alignment</span>
          </div>
        </div>
        <h3 class="landmark-title">Training language models to follow instructions with human feedback</h3>
        <p class="landmark-significance">InstructGPT introduced reinforcement learning from human feedback (RLHF) to align language models with human preferences, significantly improving helpfulness and reducing harmful outputs.</p>
        <a href="https://arxiv.org/abs/2203.02155" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">April 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Pathways</span>
            <span class="landmark-tag">Scaling</span>
          </div>
        </div>
        <h3 class="landmark-title">PaLM: Scaling Language Modeling with Pathways</h3>
        <p class="landmark-significance">PaLM demonstrated the benefits of efficiently scaling language models to 540B parameters using the Pathways system, achieving breakthrough capabilities in reasoning, multilingual tasks, and code generation.</p>
        <a href="https://arxiv.org/abs/2204.02311" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">April 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Compute-Optimal</span>
            <span class="landmark-tag">Efficiency</span>
          </div>
        </div>
        <h3 class="landmark-title">Training Compute-Optimal Large Language Models</h3>
        <p class="landmark-significance">Chinchilla redefined optimal scaling laws for LLMs, demonstrating that models were significantly undertrained and establishing new principles for balancing model size and training tokens.</p>
        <a href="https://arxiv.org/abs/2203.15556" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Open Models</span>
            <span class="landmark-tag">Transparency</span>
          </div>
        </div>
        <h3 class="landmark-title">OPT: Open Pre-trained Transformer Language Models</h3>
        <p class="landmark-significance">OPT provided the research community with an open-source alternative to large proprietary language models, advancing transparency and accessibility in AI research.</p>
        <a href="https://arxiv.org/abs/2205.01068" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Learning Paradigms</span>
            <span class="landmark-tag">Unified Training</span>
          </div>
        </div>
        <h3 class="landmark-title">UL2: Unifying Language Learning Paradigms</h3>
        <p class="landmark-significance">UL2 introduced a unified approach to pre-training language models, combining multiple learning objectives to create more versatile and effective LLMs.</p>
        <a href="https://arxiv.org/abs/2205.05131" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">June 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Emergent Abilities</span>
            <span class="landmark-tag">Scaling</span>
          </div>
        </div>
        <h3 class="landmark-title">Emergent Abilities of Large Language Models</h3>
        <p class="landmark-significance">This paper identified and documented the phenomenon of emergent abilities in large language models, capabilities that appear suddenly as model scale increases rather than improving smoothly.</p>
        <a href="https://arxiv.org/abs/2206.07682" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">June 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Evaluation</span>
            <span class="landmark-tag">Benchmarking</span>
          </div>
        </div>
        <h3 class="landmark-title">Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</h3>
        <p class="landmark-significance">BIG-bench introduced a comprehensive benchmark with 204 diverse tasks to evaluate language model capabilities, providing a more nuanced understanding of LLM strengths and weaknesses.</p>
        <a href="https://arxiv.org/abs/2206.04615" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">June 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Interfaces</span>
            <span class="landmark-tag">Systems Design</span>
          </div>
        </div>
        <h3 class="landmark-title">Language Models are General-Purpose Interfaces</h3>
        <p class="landmark-significance">METALM reframed language models as general-purpose interfaces for computing systems, demonstrating their versatility in connecting users to diverse applications and services.</p>
        <a href="https://arxiv.org/abs/2206.06336" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">September 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Alignment</span>
            <span class="landmark-tag">Dialogue</span>
          </div>
        </div>
        <h3 class="landmark-title">Improving alignment of dialogue agents via targeted human judgements</h3>
        <p class="landmark-significance">Sparrow introduced a framework for aligning dialogue agents with human values through a combination of reinforcement learning and rule-based constraints, addressing safety and helpfulness.</p>
        <a href="https://arxiv.org/abs/2209.14375" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">October 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Instruction Tuning</span>
            <span class="landmark-tag">Scaling</span>
          </div>
        </div>
        <h3 class="landmark-title">Scaling Instruction-Finetuned Language Models</h3>
        <p class="landmark-significance">This paper demonstrated the effectiveness of instruction tuning at scale, showing how models like Flan-T5 and Flan-PaLM could achieve significant improvements across hundreds of tasks.</p>
        <a href="https://arxiv.org/abs/2210.11416" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">October 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Bilingual</span>
            <span class="landmark-tag">Open Source</span>
          </div>
        </div>
        <h3 class="landmark-title">GLM-130B: An Open Bilingual Pre-trained Model</h3>
        <p class="landmark-significance">GLM-130B presented an open-source bilingual (English and Chinese) LLM with strong performance, advancing multilingual capabilities and accessibility in non-English languages.</p>
        <a href="https://arxiv.org/abs/2210.02414" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">November 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Evaluation</span>
            <span class="landmark-tag">Holistic Assessment</span>
          </div>
        </div>
        <h3 class="landmark-title">Holistic Evaluation of Language Models</h3>
        <p class="landmark-significance">HELM established a comprehensive framework for evaluating language models across multiple dimensions, including accuracy, calibration, robustness, fairness, and bias.</p>
        <a href="https://arxiv.org/abs/2211.09110" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">November 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Multilingual</span>
            <span class="landmark-tag">Open Access</span>
          </div>
        </div>
        <h3 class="landmark-title">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</h3>
        <p class="landmark-significance">BLOOM demonstrated the potential of international collaboration in creating a large-scale, multilingual LLM supporting 46 languages and 13 programming languages, advancing global AI accessibility.</p>
        <a href="https://arxiv.org/abs/2211.05100" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">November 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Scientific Knowledge</span>
            <span class="landmark-tag">Specialized Models</span>
          </div>
        </div>
        <h3 class="landmark-title">Galactica: A Large Language Model for Science</h3>
        <p class="landmark-significance">Galactica pioneered domain-specific language models for scientific knowledge, demonstrating strengths in scientific reasoning but also highlighting challenges in ensuring factual accuracy.</p>
        <a href="https://arxiv.org/abs/2211.09085" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">December 2022</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Instruction Tuning</span>
            <span class="landmark-tag">Meta-Learning</span>
          </div>
        </div>
        <h3 class="landmark-title">OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization</h3>
        <p class="landmark-significance">OPT-IML investigated generalization in instruction-tuned language models, providing insights into cross-task transfer and the factors affecting generalization to new tasks.</p>
        <a href="https://arxiv.org/abs/2212.12017" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
  </div>
</div>

<div class="year-section">
  <h2 class="year-heading">2023</h2>
  <div class="timeline">
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Instruction Tuning</span>
            <span class="landmark-tag">Dataset Design</span>
          </div>
        </div>
        <h3 class="landmark-title">The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</h3>
        <p class="landmark-significance">This paper presented a comprehensive approach to instruction tuning, introducing methods for creating high-quality datasets and training procedures that significantly improved LLM performance.</p>
        <a href="https://arxiv.org/abs/2301.13688" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">February 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Open Source</span>
            <span class="landmark-tag">Efficiency</span>
          </div>
        </div>
        <h3 class="landmark-title">LLaMA: Open and Efficient Foundation Language Models</h3>
        <p class="landmark-significance">LLaMA introduced a family of efficient foundation language models that matched or exceeded the performance of much larger models, democratizing access to powerful AI while requiring fewer computational resources.</p>
        <a href="https://arxiv.org/abs/2302.13971" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">February 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Multimodal</span>
            <span class="landmark-tag">Vision-Language</span>
          </div>
        </div>
        <h3 class="landmark-title">Language Is Not All You Need: Aligning Perception with Language Models</h3>
        <p class="landmark-significance">Kosmos-1 pioneered a multimodal LLM capable of perceiving and reasoning about visual and textual information together, breaking new ground in multimodal understanding.</p>
        <a href="https://arxiv.org/abs/2302.14045" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">March 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Recurrent Models</span>
            <span class="landmark-tag">Long Sequences</span>
          </div>
        </div>
        <h3 class="landmark-title">Resurrecting Recurrent Neural Networks for Long Sequences</h3>
        <p class="landmark-significance">LRU revitalized recurrent architectures for language modeling, introducing the Linear Recurrent Unit that combined the strengths of transformers and RNNs for processing very long sequences efficiently.</p>
        <a href="https://arxiv.org/abs/2303.06349" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">March 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Embodied</span>
            <span class="landmark-tag">Multimodal</span>
          </div>
        </div>
        <h3 class="landmark-title">PaLM-E: An Embodied Multimodal Language Model</h3>
        <p class="landmark-significance">PaLM-E unified language, vision, and action into a single model, enabling embodied intelligence and demonstrating how LLMs could power robotics and physical systems.</p>
        <a href="https://arxiv.org/abs/2303.03378" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">March 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Multimodal</span>
            <span class="landmark-tag">Capabilities</span>
          </div>
        </div>
        <h3 class="landmark-title">GPT-4 Technical Report</h3>
        <p class="landmark-significance">GPT-4 introduced a multimodal LLM with unprecedented capabilities in reasoning, specialized domains, and visual understanding, setting new benchmarks for the field and revealing emergent abilities.</p>
        <a href="https://arxiv.org/abs/2303.08774" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">April 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Visual Instruction</span>
            <span class="landmark-tag">Multimodal</span>
          </div>
        </div>
        <h3 class="landmark-title">Visual Instruction Tuning</h3>
        <p class="landmark-significance">LLaVA pioneered instruction tuning for multimodal models, enabling vision-language models to follow complex visual instructions and significantly advancing the field of multimodal AI.</p>
        <a href="https://arxiv.org/abs/2304.08485" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">April 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Model Analysis</span>
            <span class="landmark-tag">Scaling</span>
          </div>
        </div>
        <h3 class="landmark-title">Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</h3>
        <p class="landmark-significance">Pythia provided a comprehensive suite of models and tools for analyzing LLM behavior during training, enabling deeper scientific understanding of how these models learn and evolve.</p>
        <a href="https://arxiv.org/abs/2304.01373" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Self-Alignment</span>
            <span class="landmark-tag">Minimal Supervision</span>
          </div>
        </div>
        <h3 class="landmark-title">Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision</h3>
        <p class="landmark-significance">Dromedary introduced a novel approach to aligning LLMs with human values using principled self-instruction, demonstrating how models could be made more helpful and harmless with minimal human supervision.</p>
        <a href="https://arxiv.org/abs/2305.03047" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Scaling</span>
            <span class="landmark-tag">Efficiency</span>
          </div>
        </div>
        <h3 class="landmark-title">PaLM 2 Technical Report</h3>
        <p class="landmark-significance">PaLM 2 demonstrated improved efficiency in language model architecture and training, achieving superior performance with fewer parameters and maintaining strengths across reasoning, multilingual tasks, and coding.</p>
        <a href="https://arxiv.org/abs/2305.10403" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">RNN Architecture</span>
            <span class="landmark-tag">Efficiency</span>
          </div>
        </div>
        <h3 class="landmark-title">RWKV: Reinventing RNNs for the Transformer Era</h3>
        <p class="landmark-significance">RWKV introduced a novel architecture combining the parallelizable training of transformers with the efficient inference of RNNs, offering a promising alternative for language modeling with linear scaling properties.</p>
        <a href="https://arxiv.org/abs/2305.13048" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Preference Optimization</span>
            <span class="landmark-tag">RLHF Alternative</span>
          </div>
        </div>
        <h3 class="landmark-title">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</h3>
        <p class="landmark-significance">DPO introduced a simplified approach to aligning language models with human preferences, eliminating the need for separate reward models and making alignment more accessible and efficient.</p>
        <a href="https://arxiv.org/abs/2305.18290" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Reasoning</span>
            <span class="landmark-tag">Problem Solving</span>
          </div>
        </div>
        <h3 class="landmark-title">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</h3>
        <p class="landmark-significance">ToT introduced a framework for enabling LLMs to perform deliberate decision making by exploring and evaluating multiple reasoning paths, significantly improving performance on complex problems.</p>
        <a href="https://arxiv.org/abs/2305.10601" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">July 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Open Source</span>
            <span class="landmark-tag">Chat Models</span>
          </div>
        </div>
        <h3 class="landmark-title">Llama 2: Open Foundation and Fine-Tuned Chat Models</h3>
        <p class="landmark-significance">Llama 2 established new standards for open-source language models, with strong performance, safety features, and commercial availability, accelerating the adoption of LLMs in applications.</p>
        <a href="https://arxiv.org/abs/2307.09288" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">October 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Open Source</span>
            <span class="landmark-tag">Performance</span>
          </div>
        </div>
        <h3 class="landmark-title">Mistral 7B</h3>
        <p class="landmark-significance">Mistral 7B demonstrated that smaller, more efficient language models could outperform much larger models through architectural innovations and training improvements, redefining expectations for accessible AI.</p>
        <a href="https://arxiv.org/abs/2310.06825" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">December 2023</span>
          <div class="landmark-tags">
            <span class="landmark-tag">State Space Models</span>
            <span class="landmark-tag">Linear Complexity</span>
          </div>
        </div>
        <h3 class="landmark-title">Mamba: Linear-Time Sequence Modeling with Selective State Spaces</h3>
        <p class="landmark-significance">Mamba introduced selective state space models for sequence modeling, achieving transformer-level quality with linear-time computation and memory usage, offering a compelling alternative for long-sequence processing.</p>
        <a href="https://arxiv.org/abs/2312.00752" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
  </div>
</div>
<div class="year-section">
  <h2 class="year-heading">2024</h2>
  <div class="timeline">
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Efficiency</span>
            <span class="landmark-tag">MoE</span>
          </div>
        </div>
        <h3 class="landmark-title">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</h3>
        <p class="landmark-significance">DeepSeek-V2 introduced innovative approaches to mixture-of-experts architectures that substantially improved computational efficiency while maintaining high performance, making advanced language models more accessible.</p>
        <a href="https://arxiv.org/abs/2401.02954" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">February 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Open Science</span>
            <span class="landmark-tag">Transparency</span>
          </div>
        </div>
        <h3 class="landmark-title">OLMo: Accelerating the Science of Language Models</h3>
        <p class="landmark-significance">OLMo pioneered a new approach to transparent AI development, providing unprecedented access to training data, methodologies, and model checkpoints, enabling broader research participation in language model science.</p>
        <a href="https://arxiv.org/abs/2402.00838" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Architecture</span>
            <span class="landmark-tag">State Space Models</span>
          </div>
        </div>
        <h3 class="landmark-title">Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality</h3>
        <p class="landmark-significance">Mamba2 established a theoretical framework unifying transformers and state space models, enabling more efficient architectures that maintained the strengths of both approaches while overcoming their respective limitations.</p>
        <a href="https://arxiv.org/abs/2405.15747" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">May 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Open Models</span>
            <span class="landmark-tag">Performance</span>
          </div>
        </div>
        <h3 class="landmark-title">The Llama 3 Herd of Models</h3>
        <p class="landmark-significance">Llama 3 established new standards for open-source language models, demonstrating performance competitive with closed-source alternatives while providing multiple model sizes optimized for different deployment scenarios.</p>
        <a href="https://arxiv.org/abs/2404.08291" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">June 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Training Data</span>
            <span class="landmark-tag">Data Quality</span>
          </div>
        </div>
        <h3 class="landmark-title">The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale</h3>
        <p class="landmark-significance">FineWeb revolutionized training data curation for language models, introducing methods to automatically identify and extract high-quality content from web data, significantly improving model performance through better data quality.</p>
        <a href="https://arxiv.org/abs/2406.18063" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">September 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Mixture-of-Experts</span>
            <span class="landmark-tag">Open Source</span>
          </div>
        </div>
        <h3 class="landmark-title">OLMoE: Open Mixture-of-Experts Language Models</h3>
        <p class="landmark-significance">OLMoE pioneered fully open-source mixture-of-experts models that rivaled closed-source counterparts, providing the research community with transparent architectures and training methodologies for highly efficient language models.</p>
        <a href="https://arxiv.org/abs/2409.13252" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">December 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Multimodal</span>
            <span class="landmark-tag">Efficiency</span>
          </div>
        </div>
        <h3 class="landmark-title">Qwen2.5 Technical Report</h3>
        <p class="landmark-significance">Qwen2.5 represented a significant advancement in efficient multimodal models, introducing innovations in processing multiple modalities while maintaining computational efficiency and strong performance across languages.</p>
        <a href="https://arxiv.org/abs/2412.11834" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
    
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">December 2024</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Foundation Models</span>
            <span class="landmark-tag">Architecture</span>
          </div>
        </div>
        <h3 class="landmark-title">DeepSeek-V3 Technical Report</h3>
        <p class="landmark-significance">DeepSeek-V3 pushed the boundaries of language model architectures with innovative attention mechanisms and training methodologies, offering substantial improvements in efficiency and performance across a wide range of tasks.</p>
        <a href="https://arxiv.org/abs/2412.30458" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
  </div>
</div>

<div class="year-section">
  <h2 class="year-heading">2025</h2>
  <div class="timeline">
    <div class="landmark-card">
      <div class="landmark-card-content">
        <div class="landmark-meta">
          <span class="landmark-date">January 2025</span>
          <div class="landmark-tags">
            <span class="landmark-tag">Reinforcement Learning</span>
            <span class="landmark-tag">Reasoning</span>
          </div>
        </div>
        <h3 class="landmark-title">DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</h3>
        <p class="landmark-significance">DeepSeek-R1 introduced a specialized framework for enhancing reasoning capabilities in large language models through innovative reinforcement learning techniques, significantly improving performance on complex reasoning tasks beyond previous state-of-the-art systems.</p>
        <a href="https://arxiv.org/abs/2501.03755" class="landmark-read-more">
          Read Paper
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
        </a>
      </div>
    </div>
  </div>
</div>
  </div>
</div>
