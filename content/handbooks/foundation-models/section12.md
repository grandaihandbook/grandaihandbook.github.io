---
layout: default
title: "Efficient LLM Training"
description: "Investigate methods for optimizing the training of large language models."
---

<link rel="stylesheet" href="{{ '/assets/css/section-academic.css' | relative_url }}">
Distributed training, mixed precision, ZeRO, gradient accumulation, pipeline parallelism, data parallelism

<script>
  // Navigation variables - no previous for index
  window.prevSection = "/content/handbooks/foundation-models/section11/";
  window.nextSection = "/content/handbooks/foundation-models/section13/";
</script>

<script src="{{ '/assets/js/section-academic.js' | relative_url }}"></script>
